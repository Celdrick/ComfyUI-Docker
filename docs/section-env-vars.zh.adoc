[[env-vars]]
## 环境变量参考

[cols="2,2,3"]
|===
|变量名|参考值|备注

|HTTP_PROXY +
HTTPS_PROXY
|http://localhost:1081 +
http://localhost:1081
|设置 HTTP 代理。

|PIP_INDEX_URL
|'https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple'
|设置 PyPI 镜像站点。

|HF_ENDPOINT
|'https://hf-mirror.com'
|设置 HuggingFace 镜像站点。

|HF_TOKEN
|'hf_your_token'
|设置 HuggingFace
https://huggingface.co/settings/tokens[访问令牌]
（Access Token）。

|HF_HUB_CACHE
|'/root/HuggingFaceHub'
|为 HuggingFace Hub 设置模型下载目录。默认为
`~/.cache/huggingface/hub` 。

|HF_HUB_ENABLE_HF_TRANSFER
|1
|启用 HuggingFace Hub 实验性高速传输，仅对 >1000Mbps 且十分稳定的连接有意义（比如云服务器）。
https://huggingface.co/docs/huggingface_hub/hf_transfer[文档]

|TORCH_CUDA_ARCH_LIST
|7.5 +
或 +
'5.2+PTX;6.0;6.1+PTX;7.5;8.0;8.6;8.9+PTX'
|设置 PyTorch 及扩展的编译目标。
对于大多数用户，仅需为自己的 GPU 设置一个目标。
https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/[参考]

|CMAKE_ARGS
|'-DBUILD_opencv_world=ON -DWITH_CUDA=ON -DCUDA_FAST_MATH=ON -DWITH_CUBLAS=ON -DWITH_NVCUVID=ON'
|设置 CMAKE 编译参数，脚本中已默认设置，一般情况无需调整。

|===
