# Docker images for ComfyUI

*link:README.zh.adoc[＞💡中文说明点我💡＜]*

This repo is for 
https://hub.docker.com/r/yanwk/comfyui-boot[Docker images] 
that runs 
https://github.com/comfyanonymous/ComfyUI[ComfyUI] - 
a Stable Diffusion GUI powering node-based workflow.

## Quick Start - NVIDIA GPU

The supported CUDA versions for each GPU architecture are shown in the table below:

[cols="1,1,1,1,1,1,1,1,1", options="header"]
|===
| GPU Architecture | Blackwell | Hopper | Ada Lovelace | Ampere | Turing | Volta | Pascal | Maxwell

| Example GPU
| RTX 5090 | H100 | RTX 4090 | RTX 3090 | RTX 2080 | TITAN V | GTX 1080 | GTX 980

| cu129
| ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ❌ | ❌ | ❌

| cu128
| ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ❌ | ❌ | ❌

| cu126
| ❌ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️

| cu118 (discontinued)
| ❌ | ❌ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️

|===

__ Note: This CUDA compatibility limitation comes from
https://github.com/pytorch/pytorch/releases/tag/v2.8.0[PyTorch],
not NVIDIA CUDA Toolkit.
Details can be found in 
https://github.com/pytorch/pytorch/blob/main/.ci/manywheel/build_cuda.sh[PyTorch build script]. __

__ If you have an NVIDIA GPU and don't know its architecture, see
https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/[this article]. __

### CUDA 12.9: From Turing (RTX 20xx / GTX 16xx) to Blackwell (RTX 50xx)

```sh
mkdir -p storage

docker run -it --rm \
  --name comfyui-cu129 \
  --gpus all \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -e CLI_ARGS="--fast --use-pytorch-cross-attention" \
  yanwk/comfyui-boot:cu129-slim
```

### CUDA 12.6: From Maxwell (GTX 9xx) to Ada Lovelace (RTX 40xx)

```sh
mkdir -p storage

docker run -it --rm \
  --name comfyui-cu126 \
  --gpus all \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -e CLI_ARGS="" \
  yanwk/comfyui-boot:cu126-slim
```


## More image tags

Note: This repository is currently under heavy development.
The next two mainly supported image families will be `cu126` and `cu129`.

`cu121` and `cu124` images will be archived soon, as they are no longer supported by PyTorch.

`cu118` will stay for a while for compatibility usage (such as classic SD 1.5 on older hardware), but will not receive any updates.

`cu128` will stop updating after `cu129` is released.

* link:rocm/README.adoc[`rocm`]

** For AMD GPUs with ROCm.

* link:xpu/[`xpu`]

** For Intel GPUs with XPU.

* link:nightly/README.adoc[`nightly`]

** Using preview version of PyTorch (CUDA).

* link:cu121/README.adoc[`cu121`]

** Easy for ComfyUI beginners. Starts with ComfyUI, ComfyUI-Manager and the Photon (SD1.5) model.
** Using a low-privilege user within the container (easy for WSL2 deploy).
** Not recommended for Podman or rootless deploy (use any image below instead).
** Using CUDA 12.1 + Python 3.11.

* link:cu124-slim/README.adoc[`cu124-slim`]

** Similar to `cu121`, equipped with many dependencies, starts with ComfyUI and ComfyUI-Manager only.
** Downloads less. No SD model included.
** Using 'root' user within the container (easy for rootless deploy).
** Using CUDA 12.4 + Python 3.12.

* link:cu121-megapak/README.adoc[`cu121-megapak`]

** All-in-one bundle, including dev kits.
** Using CUDA 12.1 + Python 3.11.

* link:cu124-megapak/README.adoc[`cu124-megapak`]

** All-in-one bundle, including dev kits.
** Using CUDA 12.4 + Python 3.12.

* link:cu124-cn/README.adoc[`cu124-cn`]

** For users in mainland China. Using mirror sites for all download links.

* link:comfy3d-pt25/README.adoc[`comfy3d-pt25`]

** Image dedicated for https://github.com/MrForExample/ComfyUI-3D-Pack[ComfyUI-3D-Pack].


## License

link:LICENSE[Mulan Public License，Version 2]

This open source license is written and valid both in Chinese and English, how good is that!
